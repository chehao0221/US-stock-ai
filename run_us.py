import yfinance as yf
import pandas as pd
import numpy as np
import requests
import os
from xgboost import XGBRegressor
from datetime import datetime, timedelta
import warnings

# 1. åŸºæœ¬è¨­å®š
warnings.filterwarnings("ignore")
WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK_URL", "").strip()
HISTORY_FILE = "us_history.csv"

def get_us_300_pool():
    """ç²å–æ¨™æ™®500å‰300æª”è‚¡ç¥¨æ± """
    try:
        url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=10)
        df = pd.read_html(response.text)[0]
        # ä¿®æ­£ç¶­åŸºç™¾ç§‘ç¬¦è™Ÿæ ¼å¼ (ä¾‹å¦‚ BRK.B -> BRK-B)
        symbols = [s.replace('.', '-') for s in df['Symbol'].tolist()[:300]]
        print(f"âœ… æˆåŠŸç²å–è‚¡ç¥¨æ± ï¼Œå…± {len(symbols)} æª”")
        return symbols
    except Exception as e:
        print(f"âŒ ç²å–æ¸…å–®å¤±æ•— ({e})ï¼Œä½¿ç”¨å‚™ç”¨å¤§å‹è‚¡æ¸…å–®")
        return ["AAPL", "NVDA", "TSLA", "MSFT", "GOOGL", "AMZN", "META", "AVGO", "COST", "NFLX", "AMD", "SMCI", "BA"]

def compute_features(df):
    """è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ç‰¹å¾µ"""
    if df is None or len(df) < 35:
        return None
    df = df.copy()
    try:
        # è¨ˆç®—ç‰¹å¾µ
        df["mom20"] = df["Close"].pct_change(20)
        df["rsi"] = 100 - (100 / (1 + df["Close"].diff().clip(lower=0).rolling(14).mean() / ((-df["Close"].diff().clip(upper=0)).rolling(14).mean() + 1e-9)))
        df["ma20"] = df["Close"].rolling(20).mean()
        df["bias"] = (df["Close"] - df["ma20"]) / (df["ma20"] + 1e-9)
        df["sup"] = df["Low"].rolling(20).min()
        df["res"] = df["High"].rolling(20).max()
        # é æ¸¬ç›®æ¨™ï¼šæœªä¾† 5 å¤©å ±é…¬
        df["target"] = df["Close"].shift(-5).pct_change(5)
        return df
    except:
        return None

def main():
    # å®šç¾©è§€å¯Ÿæ¸…å–®èˆ‡è‚¡ç¥¨æ± 
    must_watch = ["AAPL", "NVDA", "MSFT", "TSLA", "GOOGL"]
    pool = get_us_300_pool()
    all_targets = list(dict.fromkeys(pool + must_watch)) # å»é‡
    
    results = {}
    end_date = datetime.now()
    start_date = end_date - timedelta(days=200) # çµ¦äºˆè¶³å¤ æ­·å²è³‡æ–™è¨ˆç®—æŒ‡æ¨™
    
    print(f"ğŸš€ é–‹å§‹åˆ†æ {len(all_targets)} æª”è‚¡ç¥¨...")
    
    for s in all_targets:
        try:
            # ä¸‹è¼‰è³‡æ–™
            df = yf.download(s, start=start_date, end=end_date, progress=False, repair=True)
            if df is None or len(df) < 40:
                continue
            
            # è¨ˆç®—æŒ‡æ¨™
            df_feat = compute_features(df)
            if df_feat is None: continue
            
            # æº–å‚™è¨“ç·´æ¨¡å‹
            feats = ["mom20", "rsi", "bias"]
            train_data = df_feat.dropna()
            
            if len(train_data) < 15: continue
            
            model = XGBRegressor(n_estimators=50, max_depth=3, learning_rate=0.1)
            model.fit(train_data[feats], train_data["target"])
            
            # é æ¸¬
            last_row = df_feat[feats].iloc[-1:]
            pred = model.predict(last_row)[0]
            
            results[s] = {
                "p": float(pred), 
                "c": float(df["Close"].iloc[-1]), 
                "s": float(df_feat["sup"].iloc[-1]), 
                "r": float(df_feat["res"].iloc[-1])
            }
        except Exception as e:
            continue # é‡åˆ°å ±éŒ¯è·³éè©²æª”

    # --- æ’åºé‚è¼¯ ---
    # å…ˆé¸å‡ºéæ¬Šå€¼è‚¡çš„ Top 5
    filtered_list = [s for s in results if s not in must_watch]
    top_candidates = sorted(filtered_list, key=lambda x: results[x]['p'], reverse=True)
    
    # å¦‚æœéæ¬Šå€¼è‚¡ä¸å¤  5 æª”ï¼Œå°±å¾æ¬Šå€¼è‚¡è£¡é¢è£œé€²å»
    if len(top_candidates) < 5:
        others = sorted([s for s in results if s in must_watch], key=lambda x: results[x]['p'], reverse=True)
        top_5 = (top_candidates + others)[:5]
    else:
        top_5 = top_candidates[:5]

    # --- å»ºç«‹è¨Šæ¯ ---
    today_str = datetime.now().strftime("%Y-%m-%d %H:%M")
    msg = f"ğŸ‡ºğŸ‡¸ **ç¾è‚¡ AI é ä¼°å ±å‘Š ({today_str})**\n"
    msg += "----------------------------------\n"
    
    if not results:
        msg += "âŒ éŒ¯èª¤ï¼šç„¡æ³•ç²å–ä»»ä½•è‚¡ç¥¨è³‡æ–™ï¼Œè«‹æª¢æŸ¥ç¶²è·¯æˆ– APIã€‚"
    else:
        msg += "ğŸ† **AI æ¨è–¦å¼·å‹¢è‚¡ (Top 5)**\n"
        ranks = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰", "ğŸ“ˆ", "ğŸ“ˆ"]
        for idx, s in enumerate(top_5):
            i = results[s]
            msg += f"{ranks[idx]} **{s}**: `é ä¼° {i['p']:+.2%}`\n"
            msg += f"   â”” ç¾åƒ¹: `${i['c']:.2f}` (æ”¯æ’: {i['s']:.1f} / å£“åŠ›: {i['r']:.1f})\n"

        msg += "\nğŸ’¡ **å¤§å‹æ¬Šå€¼è‚¡å‹•æ…‹**\n"
        for s in must_watch:
            if s in results:
                i = results[s]
                msg += f"â€¢ **{s}**: `{i['p']:+.2%}` (ç¾åƒ¹: ${i['c']:.2f})\n"

    # ç™¼é€ Discord
    if WEBHOOK_URL:
        requests.post(WEBHOOK_URL, json={"content": msg})
    print("âœ… å ±å‘Šå·²ç™¼é€è‡³ Discord")

if __name__ == "__main__":
    main()
