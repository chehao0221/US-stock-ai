import yfinance as yf
import pandas as pd
import numpy as np
import requests
import os
from xgboost import XGBRegressor
from datetime import datetime, timedelta
import warnings

# =========================
# åŸºæœ¬è¨­å®š
# =========================
warnings.filterwarnings("ignore")

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
HISTORY_FILE = os.path.join(BASE_DIR, "us_history.csv")
WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK_URL", "").strip()

# =========================
# ç²å–ç¾è‚¡ 300 è‚¡ç¥¨æ± 
# =========================
def get_us_300_pool():
    """ç²å–æ¨™æ™®500å‰300æª”è‚¡ç¥¨æ± """
    try:
        url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=10)
        df = pd.read_html(response.text)[0]
        # ä¿®æ­£ç¶­åŸºç™¾ç§‘ç¬¦è™Ÿæ ¼å¼ (ä¾‹å¦‚ BRK.B -> BRK-B)
        symbols = [s.replace('.', '-') for s in df['Symbol'].tolist()[:300]]
        return symbols
    except Exception as e:
        print(f"âŒ ç²å–æ¸…å–®å¤±æ•— ({e})ï¼Œä½¿ç”¨å‚™ç”¨å¤§å‹è‚¡æ¸…å–®")
        return ["AAPL", "NVDA", "TSLA", "MSFT", "GOOGL", "AMZN", "META", "AVGO", "COST", "NFLX"]

# =========================
# Discord å®‰å…¨æ¨æ’­
# =========================
def safe_post(msg: str):
    if not WEBHOOK_URL:
        print("\n--- Discord è¨Šæ¯é è¦½ ---")
        print(msg)
        return
    try:
        requests.post(WEBHOOK_URL, json={"content": msg}, timeout=15)
    except Exception as e:
        print("Discord ç™¼é€å¤±æ•—:", e)

# =========================
# ç‰¹å¾µå·¥ç¨‹
# =========================
def compute_features(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df["r"] = df["Close"].pct_change()
    df["mom20"] = df["Close"].pct_change(20)

    delta = df["Close"].diff()
    gain = delta.clip(lower=0).rolling(14).mean()
    loss = (-delta.clip(upper=0)).rolling(14).mean()
    df["rsi"] = 100 - (100 / (1 + gain / (loss + 1e-9)))

    df["ma20"] = df["Close"].rolling(20).mean()
    df["bias"] = (df["Close"] - df["ma20"]) / (df["ma20"] + 1e-9)
    df["vol_ratio"] = df["Volume"] / (df["Volume"].rolling(20).mean() + 1e-9)

    df["sup"] = df["Low"].rolling(60).min()
    df["res"] = df["High"].rolling(60).max()
    return df

# =========================
# å°å¸³èˆ‡ç´€éŒ„
# =========================
def audit_and_save(results: dict, top_keys):
    if os.path.exists(HISTORY_FILE):
        hist = pd.read_csv(HISTORY_FILE)
        hist["date"] = pd.to_datetime(hist["date"], errors="coerce").dt.date
        hist = hist.dropna(subset=["date"])
    else:
        hist = pd.DataFrame(columns=["date", "symbol", "pred_p", "pred_ret", "settled"])

    audit_msg = ""
    today_date = datetime.now().date()
    deadline = today_date - timedelta(days=8)
    unsettled = hist[(hist["settled"] == False) & (hist["date"] <= deadline)]

    if not unsettled.empty:
        audit_msg = "\nğŸ¯ **5 æ—¥é æ¸¬çµç®—å°å¸³ (US)**\n"
        for idx, r in unsettled.iterrows():
            try:
                if r["pred_p"] <= 0: continue
                price_df = yf.Ticker(r["symbol"]).history(period="5d")
                if price_df.empty: continue
                curr_p = price_df["Close"].iloc[-1]
                actual_ret = (curr_p - r["pred_p"]) / r["pred_p"]
                hit = "âœ…" if np.sign(actual_ret) == np.sign(r["pred_ret"]) else "âŒ"
                audit_msg += f"`{r['symbol']}` {r['pred_ret']:+.2%} âœ {actual_ret:+.2%} {hit}\n"
                hist.at[idx, "settled"] = True
            except: continue

    new_rows = [{"date": today_date, "symbol": s, "pred_p": results[s]["c"], 
                 "pred_ret": results[s]["p"], "settled": False} for s in top_keys]

    hist = pd.concat([hist, pd.DataFrame(new_rows)], ignore_index=True)
    hist = hist.drop_duplicates(subset=["date", "symbol"], keep="last")
    hist.to_csv(HISTORY_FILE, index=False)
    return audit_msg

# =========================
# ä¸»æµç¨‹
# =========================
def run():
    # 1. æº–å‚™è‚¡ç¥¨æ± 
    must_watch = ["AAPL", "NVDA", "TSLA", "MSFT", "GOOGL", "AMZN", "META"]
    pool = get_us_300_pool()
    watch = list(set(must_watch + pool)) # åˆä½µä¸¦å»é‡
    
    feats = ["mom20", "rsi", "bias", "vol_ratio"]
    results = {}

    print(f"[{datetime.now():%H:%M:%S}] ä¸‹è¼‰ 300 æª”ç¾è‚¡è³‡æ–™ä¸­ (è«‹ç¨å€™)...")
    # åˆ†æ‰¹ä¸‹è¼‰ä»¥é¿å… API é™é€Ÿ
    all_data = yf.download(watch, period="5y", progress=False, group_by="ticker", auto_adjust=True)

    for s in watch:
        try:
            if s not in all_data or all_data[s].empty: continue
            df = all_data[s].dropna()
            if len(df) < 120: continue

            df = compute_features(df)
            df["target"] = df["Close"].shift(-5) / df["Close"] - 1
            train_df = df.dropna()

            if len(train_df) < 60: continue

            model = XGBRegressor(n_estimators=150, max_depth=3, learning_rate=0.05, subsample=0.9, random_state=42)
            model.fit(train_df[feats], train_df["target"])

            latest_feat = train_df[feats].iloc[-1:]
            pred_ret = float(np.clip(model.predict(latest_feat)[0], -0.15, 0.15))
            last_row = train_df.iloc[-1]

            results[s] = {
                "p": pred_ret,
                "c": float(last_row["Close"]),
                "s": float(last_row["sup"]),
                "r": float(last_row["res"])
            }
        except:
            continue

    if not results:
        safe_post("âš ï¸ ç¾è‚¡ä»Šæ—¥æƒæå¤±æ•—ï¼Œè«‹æª¢æŸ¥è³‡æ–™æº")
        return

    # ç¯©é¸å…¨å ´æœ€å¼· Top 5
    top_5_keys = sorted(results.keys(), key=lambda x: results[x]['p'], reverse=True)[:5]
    audit_report = audit_and_save(results, top_5_keys)

    # çµ„åˆè¨Šæ¯
    msg = f"ğŸ‡ºğŸ‡¸ **ç¾è‚¡ AI é€²éšé æ¸¬å ±å‘Š ({datetime.now():%Y-%m-%d})**\n"
    msg += f"ğŸ’¡ å·²å®Œæˆ S&P 300 è‚¡ç¥¨æ± å…¨é¢æƒæ\n"
    msg += "----------------------------------\n"
    
    # AI æ¨è–¦åœ¨å‰
    msg += "ğŸ† **AI æ¨è–¦ Top 5 (æœ€é«˜æ½›åŠ›)**\n"
    ranks = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰", "ğŸ“ˆ", "ğŸ“ˆ"]
    for idx, s in enumerate(top_5_keys):
        i = results[s]
        msg += f"{ranks[idx]} **{s}**: `é ä¼° {i['p']:+.2%}`\n"
        msg += f"â”” ç¾åƒ¹: `${i['c']:.2f}` (æ”¯æ’: `${i['s']:.2f}` / å£“åŠ›: `${i['r']:.2f}`)\n"

    # æŒ‡å®šç›£æ§åœ¨å¾Œ
    msg += "\nğŸ” **æŒ‡å®šæ¬Šå€¼è‚¡æœªä¾†é ä¼°**\n"
    for s in must_watch:
        if s in results:
            i = results[s]
            msg += f"**{s}**: `é ä¼° {i['p']:+.2%}`\n"
            msg += f"â”” ç¾åƒ¹: `${i['c']:.2f}`\n"

    if audit_report:
        msg += audit_report

    msg += "\nğŸ’¡ *AI ç‚ºæ©Ÿç‡æ¨¡å‹ï¼Œåƒ…ä¾›ç ”ç©¶åƒè€ƒ*"
    
    if len(msg) > 1900: msg = msg[:1900] + "\n...(è¨Šæ¯å·²æˆªæ–·)"
    safe_post(msg)
    print(f"[{datetime.now():%H:%M:%S}] åˆ†æå®Œæˆ")

if __name__ == "__main__":
    run()
