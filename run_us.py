import yfinance as yf
import pandas as pd
import numpy as np
import requests
import os
from xgboost import XGBRegressor
from datetime import datetime, timedelta
import warnings

# =========================
# åŸºæœ¬è¨­å®š (ç¾è‚¡)
# =========================
warnings.filterwarnings("ignore")
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
HISTORY_FILE_US = os.path.join(BASE_DIR, "us_history.csv")
WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK_URL", "").strip()

# =========================
# å·¥å…·å‡½æ•¸ï¼šæ”¯æ’å£“åŠ›èˆ‡è‚¡ç¥¨æ± 
# =========================
def calc_sup_res_us(df):
    try:
        recent = df.iloc[-20:]
        h, l, c = recent['High'].max(), recent['Low'].min(), recent['Close'].iloc[-1]
        p = (h + l + c) / 3
        return round(2*p - h, 2), round(2*p - l, 2) # ç¾è‚¡é¡¯ç¤ºåˆ°å°æ•¸å…©ä½
    except: return 0, 0

def get_us_pool():
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
        res = requests.get(url, headers=headers, timeout=10)
        df = pd.read_html(res.text)[0]
        # yfinance æ¨™é»ç¬¦è™Ÿè™•ç† (å¦‚ BRK.B -> BRK-B)
        return [s.replace('.', '-') for s in df['Symbol'].tolist()[:300]]
    except: return ["AAPL", "NVDA", "TSLA", "MSFT", "GOOGL", "AMZN", "META"]

# =========================
# ç¾è‚¡ 5 æ—¥å›æ¸¬çµç®—
# =========================
def get_us_settle_report():
    if not os.path.exists(HISTORY_FILE_US): return ""
    try:
        df = pd.read_csv(HISTORY_FILE_US)
        df['date'] = pd.to_datetime(df['date'])
        mask = (df['settled'].astype(str).str.upper() == 'FALSE') & (df['date'] <= datetime.now() - timedelta(days=5))
        to_settle = df[mask].copy()
        if to_settle.empty: return "\nğŸ“Š **5æ—¥å›æ¸¬**: å°šç„¡å¾…çµç®—æ•¸æ“šã€‚"

        report = "\nğŸ **ç¾è‚¡ 5 æ—¥å›æ¸¬çµç®—å ±å‘Š**\n"
        syms = to_settle['symbol'].unique().tolist()
        prices = yf.download(syms, period="5d", auto_adjust=True, progress=False)['Close']
        
        for idx, row in to_settle.iterrows():
            s = row['symbol']
            try:
                curr_p = float(prices[s].dropna().iloc[-1]) if isinstance(prices, pd.DataFrame) else float(prices.iloc[-1])
                ret = (curr_p - row['pred_p']) / row['pred_p']
                win = (ret > 0 and row['pred_ret'] > 0) or (ret < 0 and row['pred_ret'] < 0)
                df.at[idx, 'settled'] = 'True'
                report += f"â€¢ `{s}`: é ä¼° {row['pred_ret']:+.2%} | å¯¦éš› `{ret:+.2%}` {'âœ…' if win else 'âŒ'}\n"
            except: continue
        df.to_csv(HISTORY_FILE_US, index=False)
        return report
    except: return ""

# =========================
# ä¸»ç¨‹åº
# =========================
def run_us():
    mag_7 = ["AAPL", "NVDA", "TSLA", "MSFT", "GOOGL", "AMZN", "META"]
    pool = get_us_pool()
    watch = list(dict.fromkeys(mag_7 + pool))
    
    print(f"ğŸ‡ºğŸ‡¸ é–‹å§‹æµ·é¸ {len(watch)} æª”ç¾è‚¡æ¨™çš„...")
    data = yf.download(watch, period="2y", auto_adjust=True, group_by="ticker", progress=False)
    
    results = {}
    feats = ["mom20", "bias", "vol_ratio"]
    
    for s in watch:
        try:
            df = data[s].dropna()
            if len(df) < 50: continue
            df["mom20"] = df["Close"].pct_change(20)
            df["bias"] = (df["Close"] - df["Close"].rolling(20).mean()) / df["Close"].rolling(20).mean()
            df["vol_ratio"] = df["Volume"] / df["Volume"].rolling(20).mean()
            df["target"] = df["Close"].shift(-5) / df["Close"] - 1
            
            train = df.dropna().iloc[-300:]
            model = XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.05).fit(train[feats], train["target"])
            pred = float(model.predict(df[feats].iloc[-1:])[0])
            sup, res = calc_sup_res_us(df)
            results[s] = {"p": pred, "c": float(df["Close"].iloc[-1]), "sup": sup, "res": res}
        except: continue

    # çµ„åˆè¨Šæ¯ (æ’ç‰ˆæ¯”ç…§åœ–äºŒ)
    msg = f"ğŸ‡ºğŸ‡¸ **ç¾è‚¡ AI é€²éšé æ¸¬å ±å‘Š ({datetime.now():%Y-%m-%d})**\n"
    msg += "------------------------------------------\n\n"
    msg += "ğŸ† **AI æµ·é¸ Top 5 (ç¾è‚¡æ½›åŠ›è‚¡)**\n"
    
    horses = {k: v for k, v in results.items() if k not in mag_7}
    top_5 = sorted(horses, key=lambda x: horses[x]["p"], reverse=True)[:5]
    
    for i, s in enumerate(top_5):
        r = results[s]
        msg += f"{['ğŸ¥‡','ğŸ¥ˆ','ğŸ¥‰','ğŸ“ˆ','ğŸ“ˆ'][i]} **{s}**: é ä¼° `{r['p']:+.2%}`\n"
        msg += f" â”” ç¾åƒ¹: `{r['c']:.2f}` (æ”¯æ’: `{r['sup']}` / å£“åŠ›: `{r['res']}`)\n"

    msg += "\nğŸ’ **ç§‘æŠ€å·¨é ­ç›£æ§ (Magnificent 7)**\n"
    for s in mag_7:
        if s in results:
            r = results[s]
            msg += f"**{s}**: é ä¼° `{r['p']:+.2%}`\n â”” ç¾åƒ¹: `{r['c']:.2f}`\n"

    # åŠ ä¸Šå›æ¸¬å ±å‘Š
    msg += get_us_settle_report()
    msg += "\nğŸ’¡ AI é æ¸¬åƒ…ä¾›åƒè€ƒï¼Œç¾è‚¡æ³¢å‹•å¤§è«‹æ³¨æ„é¢¨éšªã€‚"

    if WEBHOOK_URL:
        requests.post(WEBHOOK_URL, json={"content": msg[:1900]}, timeout=15)
    else: print(msg)

    # å­˜æª”ä¾›æœªä¾†çµç®—
    new_hist = [{"date": datetime.now().date(), "symbol": s, "pred_p": results[s]['c'], "pred_ret": results[s]['p'], "settled": "False"} for s in (top_5 + mag_7) if s in results]
    pd.DataFrame(new_hist).to_csv(HISTORY_FILE_US, mode='a', header=not os.path.exists(HISTORY_FILE_US), index=False)

if __name__ == "__main__":
    run_us()
