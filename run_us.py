import yfinance as yf
import pandas as pd
import numpy as np
import requests
import os
from xgboost import XGBRegressor
from datetime import datetime
import warnings

# =========================
# åŸºæœ¬è¨­å®š
# =========================
warnings.filterwarnings("ignore")
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
HISTORY_FILE = os.path.join(BASE_DIR, "us_history.csv")
WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK_URL", "").strip()

# =========================
# è‚¡ç¥¨æ±  (S&P 500 å‰ 300 æª”)
# =========================
def get_us_300_pool():
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        res = requests.get("https://en.wikipedia.org/wiki/List_of_S%26P_500_companies", headers=headers, timeout=10)
        df = pd.read_html(res.text)[0]
        # ä¿®æ­£ç¾è‚¡ä»£ç¢¼ä¸­çš„é»ï¼ˆå¦‚ BRK.B æ”¹ç‚º BRK-Bï¼‰ä»¥ç¬¦åˆ yfinance æ ¼å¼
        symbols = [s.replace('.', '-') for s in df['Symbol'].tolist()]
        return symbols[:300]
    except Exception as e:
        print(f"æ± åŒ–æŠ“å–å¤±æ•—: {e}")
        return ["AAPL", "NVDA", "TSLA", "MSFT", "GOOGL", "AMZN", "META"]

# =========================
# å¤§ç›¤ç’°å¢ƒç›£æ¸¬ (S&P 500)
# =========================
def get_market_context():
    try:
        idx = yf.download("^GSPC", period="1y", auto_adjust=True, progress=False)
        if idx.empty: return True, 0, 0, None
        idx["ma60"] = idx["Close"].rolling(60).mean()
        curr_p = float(idx["Close"].iloc[-1])
        ma60_p = float(idx["ma60"].iloc[-1])
        return (curr_p > ma60_p), curr_p, ma60_p, idx
    except:
        return True, 0, 0, None

# =========================
# é€²éšç‰¹å¾µå·¥ç¨‹
# =========================
def compute_features(df, market_df=None):
    df = df.copy()
    
    # 1. åŸºç¤å‹•èƒ½èˆ‡è¶…è²·è¶…è³£
    df["mom20"] = df["Close"].pct_change(20)
    delta = df["Close"].diff()
    gain = delta.clip(lower=0).rolling(14).mean()
    loss = (-delta.clip(upper=0)).rolling(14).mean()
    df["rsi"] = 100 - (100 / (1 + gain / (loss + 1e-9)))
    
    # 2. ä¹–é›¢ç‡èˆ‡é‡æ¯”
    df["ma20"] = df["Close"].rolling(20).mean()
    df["bias"] = (df["Close"] - df["ma20"]) / (df["ma20"] + 1e-9)
    df["vol_ratio"] = df["Volume"] / (df["Volume"].rolling(20).mean() + 1e-9)
    
    # 3. ATR æ³¢å‹•ç‡æŒ‡æ¨™
    hl = df["High"] - df["Low"]
    hc = (df["High"] - df["Close"].shift()).abs()
    lc = (df["Low"] - df["Close"].shift()).abs()
    df["atr"] = pd.concat([hl, hc, lc], axis=1).max(axis=1).rolling(14).mean()
    
    # 4. ç›¸å°å¼·åº¦ (RS Index) - ç›¸å°æ–¼ S&P 500
    if market_df is not None:
        mkt_ret = market_df["Close"].pct_change(20)
        df["rs_index"] = df["Close"].pct_change(20) - mkt_ret.reindex(df.index)
    else:
        df["rs_index"] = 0
    
    # 5. æˆäº¤é‡‘é¡ (æµå‹•æ€§)
    df["avg_amount"] = (df["Close"] * df["Volume"]).rolling(5).mean()
    return df

# =========================
# ç´€éŒ„èˆ‡å°å¸³
# =========================
def audit_and_save(results, top_keys):
    if os.path.exists(HISTORY_FILE):
        hist = pd.read_csv(HISTORY_FILE)
        hist["date"] = pd.to_datetime(hist["date"]).dt.date
    else:
        hist = pd.DataFrame(columns=["date", "symbol", "pred_p", "pred_ret", "settled"])
    
    today = datetime.now().date()
    new_rows = []
    for s in top_keys:
        if results[s]["c"] <= 0: continue
        new_rows.append({
            "date": today,
            "symbol": s,
            "pred_p": results[s]["c"],      # ç´€éŒ„ç¾åƒ¹ä¾›çµç®—
            "pred_ret": results[s]["p"],    # ç´€éŒ„ AI é æ¸¬æ¼²å¹…
            "settled": False
        })
    
    if new_rows:
        hist = pd.concat([hist, pd.DataFrame(new_rows)], ignore_index=True)
        hist = hist.drop_duplicates(subset=["date", "symbol"], keep="last")
        hist.to_csv(HISTORY_FILE, index=False)

# =========================
# ä¸»åˆ†ææµç¨‹
# =========================
def run():
    is_bull, mkt_p, mkt_ma, mkt_df = get_market_context()
    must_watch = ["AAPL", "NVDA", "TSLA", "MSFT"]
    pool = get_us_300_pool()
    watch = list(set(must_watch + pool))
    
    print(f"ğŸš€ ç¾è‚¡ AI åˆ†æå•Ÿå‹• | å¸‚å ´è¶¨å‹¢ï¼š{'å¤šé ­' if is_bull else 'ç©ºé ­ï¼ˆé˜²ç¦¦æ¨¡å¼ï¼‰'}")
    
    # ä¸€æ¬¡æ€§æŠ“å– 300 æª”æ¨™çš„æ•¸æ“š
    all_data = yf.download(watch, period="5y", group_by="ticker", auto_adjust=True, progress=False)
    
    feats = ["mom20", "rsi", "bias", "vol_ratio", "rs_index"]
    results = {}
    MIN_AMOUNT = 10_000_000 # é–€æª»ï¼š1000è¬ç¾é‡‘

    for s in watch:
        try:
            if s not in all_data or all_data[s].empty: continue
            
            df = all_data[s].dropna()
            if len(df) < 150: continue
            
            df = compute_features(df, market_df=mkt_df)
            last = df.iloc[-1]
            
            # 1. æµå‹•æ€§æ¿¾ç¶²
            if last["avg_amount"] < MIN_AMOUNT: continue

            # 2. è¨“ç·´é›†æº–å‚™ (è¿‘ 500 æ ¹ K ç·š)
            df["target"] = df["Close"].shift(-5) / df["Close"] - 1
            train = df.dropna().iloc[-500:]
            
            if len(train) < 100: continue

            # 3. æ¨¡å‹è¨“ç·´
            model = XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.05, random_state=42)
            model.fit(train[feats], train["target"])
            
            # 4. é æ¸¬
            pred = float(np.clip(model.predict(train[feats].iloc[-1:])[0], -0.15, 0.15))
            
            # 5. é¢¨éšªå¹²é 
            if not is_bull: pred *= 0.5  # å¤§ç›¤ç©ºé ­é™æ¬Š
            if last["atr"] > df["atr"].mean() * 1.5: pred *= 0.8  # é«˜æ³¢å‹•é™æ¬Š
            if pred < 0.01: pred = 0  # å™ªéŸ³ä¿è­·

            results[s] = {
                "p": pred,
                "c": float(last["Close"]),
                "rs": float(last["rs_index"])
            }
        except:
            continue

    # æ’åºé¸å‡º Top 5 (æ’é™¤å›ºå®šç›£æ¸¬è‚¡)
    horses = {k: v for k, v in results.items() if k not in must_watch}
    top_keys = sorted(horses, key=lambda x: horses[x]["p"], reverse=True)[:5]
    final_keys = [k for k in top_keys if horses[k]["p"] > 0]

    # å„²å­˜èˆ‡å°å¸³
    audit_and_save(results, final_keys)

    # å ±å‘Šçµ„è£
    msg = f"ğŸ‡ºğŸ‡¸ **ç¾è‚¡ AI é€²éšé å ± ({datetime.now():%m/%d})**\n"
    msg += f"{'ğŸ“ˆ å¤šé ­ç’°å¢ƒ' if is_bull else 'âš ï¸ ç©ºé ­è­¦ç¤º (é æ¸¬å·²é™æ¬Š)'} | æŒ‡æ•¸: {mkt_p:.1f}\n"
    msg += "----------------------------------\n"
    
    if not final_keys:
        msg += "ğŸ’¡ å¸‚å ´ä¿¡è™Ÿä¸è¶³ï¼Œå»ºè­°ä¿å®ˆè§€æœ›ã€‚\n"
    else:
        for i, s in enumerate(final_keys):
            r = results[s]
            msg += f"{['ğŸ¥‡','ğŸ¥ˆ','ğŸ¥‰','ğŸ“ˆ','ğŸ“ˆ'][i]} **{s}** é ä¼° `{r['p']:+.2%}` | RS:{'å¼·' if r['rs']>0 else 'å¼±'}\n"

    # æ¬Šå€¼ç›£æ¸¬
    msg += "\nğŸ” **æ¬Šå€¼/ç›£æ¸¬æ¨™çš„**\n"
    for s in must_watch:
        if s in results:
            msg += f"`{s}` é ä¼° `{results[s]['p']:+.2%}`\n"
    
    if WEBHOOK_URL:
        try:
            requests.post(WEBHOOK_URL, json={"content": msg[:1900]}, timeout=15)
        except:
            print("Webhook å‚³é€å¤±æ•—")
    else:
        print(msg)

if __name__ == "__main__":
    run()
